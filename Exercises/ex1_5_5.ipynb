{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## exercise 1.5.5\n",
    "import importlib_resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# In this exercise we will rely on pandas for some of the processing steps:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/messy_data\")\n",
    "filename = foldername.joinpath(\"messy_data.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should inspect it manually to understand the format and content\n",
    "print(\"\\nLocation of the messy_data folder: {}\".format(foldername))\n",
    "print(\"\\nLocation of the messy_data.data file: {}\\n\".format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data = pd.read_csv(filename, sep=\"\\t\", header=1)\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data = messy_data.drop(messy_data.index[0])\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the attribute names:\n",
    "attributeNames = np.asarray(messy_data.columns)\n",
    "# As we progress through this script, we might change which attributes are\n",
    "# stored where. For simplicity in presenting the processing steps, we wont\n",
    "# keep track of those changes in attributeNames in this example script.\n",
    "\n",
    "# The last column is a unique string for each observation defining the\n",
    "# car make and model. We decide to extract this in a variable for itself\n",
    "# for now, and then remove it from messy_data:\n",
    "car_names = np.array(messy_data.carname)\n",
    "messy_data = messy_data.drop([\"carname\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect messy data by e.g.:\n",
    "print(messy_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, youll see that some of the missing values from the data\n",
    "# has already been represented as NaNs (in the displacement column).\n",
    "# However, these were only the places where an empty element was in the file.\n",
    "# First off, we remove the question marks in displacement and replace\n",
    "# them with not a number, NaN:\n",
    "messy_data.displacement = messy_data.displacement.str.replace(\"?\", \"NaN\")\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we remove the formatting for a thousand seperator that is\n",
    "# present for the weight attribute:\n",
    "messy_data.weight = messy_data.weight.str.replace(\"'\", \"\")\n",
    "# And lastly, we replace all the commas that were used as decimal seperatos\n",
    "# in the accceleration attribute with dots:\n",
    "messy_data.acceleration = messy_data.acceleration.str.replace(\",\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data has some zero values that the README.txt tolds us were missing\n",
    "# values - this was specifically for the attributes mpg and displacement,\n",
    "# so we're careful only to replace the zeros in these attributes, since a\n",
    "# zero might be correct for some other variables:\n",
    "messy_data.mpg = messy_data.mpg.replace({\"0\": np.nan})\n",
    "messy_data.displacement = messy_data.displacement.replace({\"0\": np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We later on find out that a value of 99 for the mpg is not value that is\n",
    "# within reason for the MPG of the cars in this dataset. The observations\n",
    "# that has this value of MPG is therefore incorrect, and we should treat\n",
    "# the value as missing. How would you add a line of code to this data\n",
    "# cleanup script to account for this information?\n",
    "\n",
    "messy_data.mpg = messy_data.mpg.replace({\"99\": np.nan})\n",
    "\n",
    "## X,y-format\n",
    "# If the modelling problem of interest was a classification problem where\n",
    "# we wanted to classify the origin attribute, we could now identify obtain\n",
    "# the data in the X,y-format as so:\n",
    "data = np.array(messy_data.values, dtype=np.float64)\n",
    "X_c = data[:, :-1].copy()\n",
    "y_c = data[:, -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, if the problem of interest was to model the MPG based on the\n",
    "# other attributes (a regression problem), then the X,y-format is\n",
    "# obtained as:\n",
    "X_r = data[:, 1:].copy()\n",
    "y_r = data[:, 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since origin is categorical variable, we can do as in previos exercises\n",
    "# and do a one-out-of-K encoding:\n",
    "origin = np.array(X_r[:, -1], dtype=int).T - 1\n",
    "K = origin.max() + 1\n",
    "origin_encoding = np.zeros((origin.size, K))\n",
    "origin_encoding[np.arange(origin.size), origin] = 1\n",
    "X_r = np.concatenate((X_r[:, :-1], origin_encoding), axis=1)\n",
    "# Since the README.txt doesn't supply a lot of information about what the\n",
    "# levels in the origin variable mean, you'd have to either make an educated\n",
    "# guess based on the values in the context, or preferably obtain the\n",
    "# information from any papers that might be references in the README.\n",
    "# In this case, you can inspect origin and car_names, to see that (north)\n",
    "# american makes are all value 0 (try looking at car_names[origin == 0],\n",
    "# whereas origin value 1 is European, and value 2 is Asian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values\n",
    "# In the above X,y-matrices, we still have the missing values. In the\n",
    "# following we will go through how you could go about handling the missing\n",
    "# values before making your X,y-matrices as above.\n",
    "\n",
    "# Once we have identified all the missing data, we have to handle it\n",
    "# some way. Various apporaches can be used, but it is important\n",
    "# to keep it mind to never do any of them blindly. Keep a record of what\n",
    "# you do, and consider/discuss how it might affect your modelling.\n",
    "\n",
    "# The simplest way of handling missing values is to drop any records\n",
    "# that display them, we do this by first determining where there are\n",
    "# missing values:\n",
    "missing_idx = np.isnan(data)\n",
    "# Observations with missing values have a row-sum in missing_idx\n",
    "# which is greater than zero:\n",
    "obs_w_missing = np.sum(missing_idx, 1) > 0\n",
    "data_drop_missing_obs = data[np.logical_not(obs_w_missing), :]\n",
    "# This reduces us to 15 observations of the original 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach is to first investigate where the missing values are.\n",
    "# A quick way to do this is to visually look at the missing_idx:\n",
    "plt.title(\"Visual inspection of missing values\")\n",
    "plt.imshow(missing_idx)\n",
    "plt.ylabel(\"Observations\")\n",
    "plt.xlabel(\"Attributes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From such a plot, we can see that the issue is the third column, the\n",
    "# displacement attribute. This can be confirmed by e.g. doing:\n",
    "# np.sum(missing_idx, 0)\n",
    "# which shows that 12 observations are missing a value in the third column.\n",
    "# Therefore, another way to move forward is to disregard displacement\n",
    "# (for now) and remove the attribute. We then remove the few\n",
    "# remaining observations with missing values:\n",
    "cols = np.ones((data.shape[1]), dtype=bool)\n",
    "cols[2] = 0\n",
    "data_wo_displacement = data[:, cols]\n",
    "obs_w_missing_wo_displacement = np.sum(np.isnan(data_wo_displacement), 1) > 0\n",
    "data_drop_disp_then_missing = data[np.logical_not(obs_w_missing_wo_displacement), :]\n",
    "# Now we have kept all but two of the observations. This however, doesn't\n",
    "# necesarrily mean that this approach is superior to the previous one,\n",
    "# since we have now also lost any and all information that we could have\n",
    "# gotten from the displacement attribute.\n",
    "\n",
    "# One could impute the missing values - \"guess them\", in some\n",
    "# sense - while trying to minimize the impact of the guess.\n",
    "# A simply way of imputing them is to replace the missing values\n",
    "# with the median of the attribute. We would have to do this for the\n",
    "# missing values for attributes 1 and 3:\n",
    "data_imputed = data.copy()\n",
    "for att in [0, 2]:\n",
    "    # We use nanmedian to ignore the nan values\n",
    "    impute_val = np.nanmedian(data[:, att])\n",
    "    idx = missing_idx[:, att]\n",
    "    data_imputed[idx, att] = impute_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
